{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7921df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "from together import Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d62299fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_caption(base64_image: base64) -> str:\n",
    "    \"\"\"Image captioning by using a Vision Language Model\"\"\"\n",
    "    \n",
    "    client = Together()\n",
    "    prompt = \"Give a suitable caption for the provided image\"\n",
    "    \n",
    "    stream = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-Vision-Free\",\n",
    "    # Other vision model choices\n",
    "    # Meta Llama 3.2 90B Vision Instruct Turbo $ 1.2\n",
    "    # Meta Llama 3.2 11B Vision Instruct Turbo $ 0.18\n",
    "    # Meta Llama Guard 3 11B Vision Turbo $ 0.18\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    "    )\n",
    "    \n",
    "    caption = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.choices and chunk.choices[0].delta:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            caption += content\n",
    "    \n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "853f3c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_table_cleaning(table_str: str):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a Markdown formatting assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "        I have extracted a table from a PDF using OCR. It is in the form of a nested list of rows (some cells are `null` meaning continuation of above cell). Please convert this into a clean, readable markdown table.\n",
    "\n",
    "        - If some cells are meant to span multiple rows, fill in the blanks based on context.\n",
    "        - Properly handle newlines inside cells.\n",
    "        - DO NOT add any explanations or extra text.\n",
    "        - Just return the cleaned markdown table â€” no headings, no descriptions, no comments.\n",
    "\n",
    "        Here is the table:\n",
    "        {table_str}\n",
    "        \"\"\"\n",
    "        }\n",
    "        ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f59ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_table(table):\n",
    "\n",
    "    table_str = json.dumps(table, indent=2)\n",
    "    client = Together()\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
    "    messages=prompt_table_cleaning(table_str)\n",
    "    )\n",
    "    md_table = response.choices[0].message.content\n",
    "    return md_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66e64aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "        Processes a PDF, extracts text, images (gets captions), and tables,\n",
    "        and returns a Markdown string.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    print(f\"Processing PDF: {pdf_path} with {len(doc)} pages.\")\n",
    "    c = 0\n",
    "    final_doc = []\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        \n",
    "        page_content = []\n",
    "        page_content.append(f\"\\n## Page {page_num + 1}\\n\")\n",
    "        \n",
    "        # Extracting Text\n",
    "        text = page.get_text(\"text\")\n",
    "        if text.strip():\n",
    "            page_content.append(\"### Text\\n\")\n",
    "            page_content.append(text.strip())\n",
    "            page_content.append(\"\\n\")\n",
    "            \n",
    "        \n",
    "        # Extracting Images and getting caption\n",
    "        image_list = page.get_images(full=True)\n",
    "        print(f\"Page: {page_num}\")\n",
    "        if image_list:\n",
    "            # print(f\"YESS: {page_num}\")\n",
    "            page_content.append(\"### Images\\n\")\n",
    "            \n",
    "            for img in image_list:\n",
    "                \n",
    "                # get the XREF of the image\n",
    "                xref = img[0]\n",
    "\n",
    "                base_image = doc.extract_image(xref)\n",
    "                # base_image is a dictionary with lot of info\n",
    "                \n",
    "                # this is the bytes of the image\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                \n",
    "                # converting it to base 64 to make it easy to use with Together AI\n",
    "                base64_image = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "                \n",
    "                # get the image extension(useful for saving the img)\n",
    "                # image_ext = base_image[\"ext\"]\n",
    "                \n",
    "                # Caption the image and add it to our page_content\n",
    "                caption = get_image_caption(base64_image)\n",
    "                page_content.append(caption)\n",
    "                page_content.append(\"\\n\")\n",
    "\n",
    "        \n",
    "        # Extracting tables\n",
    "        tables = page.find_tables()\n",
    "        if tables.tables:\n",
    "            \n",
    "            page_content.append(\"### Table\\n\")\n",
    "            for table in tables.tables:\n",
    "                \n",
    "                data = table.extract() # List[List[str]]\n",
    "                md_table = process_table(data)\n",
    "                \n",
    "                page_content.append(md_table)\n",
    "                page_content.append(\"\\n\")\n",
    "\n",
    "        final_doc.extend(page_content)\n",
    "    return final_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f976cb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = 'Data/Applications of Transformers.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73b70cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: Data/Applications of Transformers.pdf with 58 pages.\n",
      "Page: 0\n",
      "Page: 1\n",
      "Page: 2\n",
      "Page: 3\n",
      "Page: 4\n",
      "Page: 5\n",
      "Page: 6\n",
      "Page: 7\n",
      "Page: 8\n",
      "Page: 9\n",
      "Page: 10\n",
      "Page: 11\n",
      "Page: 12\n",
      "Page: 13\n",
      "Page: 14\n",
      "Page: 15\n",
      "Page: 16\n",
      "Page: 17\n",
      "Page: 18\n",
      "Page: 19\n",
      "Page: 20\n",
      "Page: 21\n",
      "Page: 22\n",
      "Page: 23\n",
      "Page: 24\n",
      "Page: 25\n",
      "Page: 26\n",
      "Page: 27\n",
      "Page: 28\n",
      "Page: 29\n",
      "Page: 30\n",
      "Page: 31\n",
      "Page: 32\n",
      "Page: 33\n",
      "Page: 34\n",
      "Page: 35\n",
      "Page: 36\n",
      "Page: 37\n",
      "Page: 38\n",
      "Page: 39\n",
      "Page: 40\n",
      "Page: 41\n",
      "Page: 42\n",
      "Page: 43\n",
      "Page: 44\n",
      "Page: 45\n",
      "Page: 46\n",
      "Page: 47\n",
      "Page: 48\n",
      "Page: 49\n",
      "Page: 50\n",
      "Page: 51\n",
      "Page: 52\n",
      "Page: 53\n",
      "Page: 54\n",
      "Page: 55\n",
      "Page: 56\n",
      "Page: 57\n"
     ]
    }
   ],
   "source": [
    "md_text = process_pdf(PDF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2291a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_str = ''.join(md_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99f1203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(md_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f47bf3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
